networks:
  demo:

x-n8n: &service-n8n
  image: n8nio/n8n:stable
  networks: ['demo']
  environment:
    - DB_TYPE=postgresdb
    - DB_POSTGRESDB_HOST=${DB_POSTGRESDB_HOST:-postgres}
    - DB_POSTGRESDB_USER=${DB_POSTGRESDB_USER}
    - DB_POSTGRESDB_PASSWORD=${DB_POSTGRESDB_PASSWORD}
    - DB_POSTGRESDB_DATABASE=${DB_POSTGRESDB_DATABASE}
    - DB_POSTGRESDB_POOL_SIZE=${DB_POSTGRESDB_POOL_SIZE:-10}
    - DB_POSTGRESDB_PORT=${DB_POSTGRESDB_PORT:-5432}
    - DB_POSTGRESDB_SSL_CERT=${DB_POSTGRESDB_SSL_CERT:-/etc/ssl/certs/postgres.crt}
    - DB_POSTGRESDB_SSL_ENABLED=true
    - DB_POSTGRESDB_SSL_REJECT_UNAUTHORIZED=false
    - WEBHOOK_URL=${WEBHOOK_URL:-http://localhost:5678}
    - N8N_DIAGNOSTICS_ENABLED=false
    - N8N_PERSONALIZATION_ENABLED=false
    - N8N_ENFORCE_SETTINGS_FILE_PERMISSIONS=true
    - N8N_RUNNERS_ENABLED=true
    - N8N_ENCRYPTION_KEY
    - N8N_USER_MANAGEMENT_JWT_SECRET
  env_file:
    - .env

services:
  n8n-import:
    <<: *service-n8n
    hostname: n8n-import
    container_name: n8n-import
    entrypoint: /bin/sh
    command:
      - "-c"
      - "chown -R 1000:1000 /opt/custom-certificates && n8n import:credentials --separate --input=/backup/credentials && n8n import:workflow --separate --input=/backup/workflows"
    volumes:
      - ./volumes/n8n/backup:/backup
      - ./volumes/certificates:/opt/custom-certificates

  n8n:
    <<: *service-n8n
    hostname: n8n
    container_name: n8n
    restart: unless-stopped
    ports:
      - 5678:5678
    volumes:
      - ./volumes/n8n/storage:/home/node/.n8n
      - ./volumes/n8n/backup:/backup
      - ./volumes/shared:/data/shared
    depends_on:
      n8n-import:
        condition: service_completed_successfully

  qdrant:
    image: qdrant/qdrant
    hostname: qdrant
    container_name: qdrant
    networks: ['demo']
    restart: unless-stopped
    ports:
      - 6333:6333
    volumes:
      - ./volumes/qdrant:/qdrant/storage

  litellm:
    build:
      context: .
      args:
        target: runtime
    image: ghcr.io/berriai/litellm:main-stable
    hostname: litellm
    container_name: litellm
    networks: ['demo']
    restart: unless-stopped
    ports:
      - 4000:4000
    volumes:
      - ./config.yaml:/app/config.yaml
    command:
      - "--config=/app/config.yaml"
    environment:
        DATABASE_URL: ${DATABASE_URL:-postgres://llmproxy:dbpassword9090@db:5432/litellm}
        STORE_MODEL_IN_DB: "True" # allows adding models to proxy via UI
    env_file:
      - .env # Load local .env file
    healthcheck:  # Defines the health check configuration for the container
      test: [ "CMD", "curl", "-f", "http://localhost:4000/health/liveliness || exit 1" ]  # Command to execute for health check
      interval: 30s  # Perform health check every 30 seconds
      timeout: 10s   # Health check command times out after 10 seconds
      retries: 3     # Retry up to 3 times if health check fails
      start_period: 40s  # Wait 40 seconds after container start before beginning health checks

  caddy:
    build: 
      context: .
      dockerfile: Dockerfile
    hostname: caddy
    container_name: caddy
    networks: ['demo']
    restart: unless-stopped
    env_file:
      - .env
    ports:
      - 80:80
      - 443:443
    volumes:
      - ./volumes/caddy/data:/data
      - ./volumes/caddy/config:/config
      - ./Caddyfile:/etc/caddy/Caddyfile
      
  prometheus:
    image: prom/prometheus
    volumes:
      - ./volumes/prometheus:/prometheus
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    ports:
      - "9090:9090"
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--storage.tsdb.retention.time=15d'
    restart: always
